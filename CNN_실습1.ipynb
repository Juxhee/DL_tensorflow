{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-1 \n",
    "# CNN basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 벡터에 필터로 추출되어 여러번 움직이며 convolution\n",
    "# convolution한 값들을 subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17109e85388>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype = np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3),cmap = 'Greys') # 이미지쇼를 활용해서 시각화 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image : 1,3,3,1 image, Filter : 2,2,1,1, Stride : 1 * 1, padding : VALID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAC7CAYAAADGxxq1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAJd0lEQVR4nO3dX6ik9X3H8fenWvXCdrO6TVxMUiPVtCYtxCzWJhClRjBS3EAsmJtoURbbSqFXNQgp5Kaam9Jg2rBJQ7UXRupFsymGEmuWBMpal6LZxGBcpcFll5iYsmVpm3TTby/mSTqczNlzvs5zZuas7xcM88w8v/P8vox8fP7sD76pKiRt3s8tuwBpuzE0UpOhkZoMjdRkaKQmQyM1zRWaJBcl+XKSF4b3neuM+3GSZ4bXgXnmlJYt8/w7TZJPAD+oqvuT3AvsrKo/mTHuVFVdOEed0sqYNzTPA9dX1Ykku4GDVfX2GeMMjc4a897TvKmqTgAM729cZ9wFSQ4nOZTkg3POKS3VuRsNSPIEcMmMXfc15nlrVR1PcjnwZJIjVfXijLn2AfuGj+9uHP9178ILPZF3nTp16vtV9Uvdv9swNFX1/vX2Jflukt1Tl2evrHOM48P7S0kOAu8CfiY0VbUf2D8c20VxDXv27Fl2CdvOwYMHv/Na/m7ey7MDwO3D9u3AF9YOSLIzyfnD9i7gvcBzc84rLc28obkfuDHJC8CNw2eS7Eny2WHMrwGHkzwLfAW4v6oMjbatDS/PzqSqXgVumPH9YeCuYfufgV+fZx5plbgiQGoyNFKToZGaDI3UZGikJkMjNRkaqcnQSE2GRmoyNFKToZGaDI3UZGikJkMjNRkaqcnQSE2GRmoyNFKToZGaDI3UZGikJkMjNRkaqcnQSE2GRmoyNFKToZGaDI3UZGikplFCk+SmJM8nOTo0rF27//wkjw77n0py2RjzSsswd2iSnAN8CvgAcBXw4SRXrRl2J/DvVfUrwJ8DD8w7r7QsY5xprgGOVtVLVfUj4PPA3jVj9gIPDduPATckyQhzSws3RmguBV6e+nxs+G7mmKo6DZwELh5hbmnh5uqENph1xljbZHYzY9Z2d5ZW0hhnmmPAW6Y+vxk4vt6YJOcCO4AfrD1QVe2vqj1VZatirawxQvM0cEWStyU5D7iNSdfnadNdoG8FnqwqW55rW5r78qyqTie5B/hH4Bzgc1X1zSQfBw5X1QHgr4G/TXKUyRnmtnnnlZZljHsaqupx4PE1331savu/gd8dYy5p2VwRIDUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRS06K6O9+R5HtJnhled40xr7QMc7famOrufCOTjmdPJzlQVc+tGfpoVd0z73zSsi2qu7N01hijqdOs7s6/OWPch5K8D/g28MdV9fKMMT915ZVXsn///hHKe3247rrrll3CtpPM6p+8sTHONJvp3PxF4LKq+g3gCeChmQdK9iU5nOTwyZMnRyhNGt9CujtX1atV9cPh42eAd8860HR35x07doxQmjS+hXR3TrJ76uMtwLdGmFdaikV1d/6jJLcAp5l0d75j3nmlZVlUd+ePAh8dYy5p2VwRIDUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRS01jdnT+X5JUk31hnf5J8cuj+/PUkV48xr7QMY51p/ga46Qz7PwBcMbz2AX810rzSwo0Smqr6KpNmTevZCzxcE4eAN6zpjiZtG4u6p5nVAfrSBc0tjWpRodlMB2i7O2tbWFRoNuwADXZ31vawqNAcAD4yPEW7FjhZVScWNLc0qlEa1SZ5BLge2JXkGPCnwM8DVNWnmTSxvRk4Cvwn8HtjzCstw1jdnT+8wf4C/nCMuaRlc0WA1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNhkZqMjRSk6GRmgyN1GRopCZDIzUZGqnJ0EhNi+rufH2Sk0meGV4fG2NeaRlGabXBpLvzg8DDZxjztar6nZHmk5ZmUd2dpbPGIu9pfivJs0m+lOQdC5xXGlUmTcpGOFByGfAPVfXOGft+EfjfqjqV5GbgL6rqihnj9gH7ho/vBGbeIy3ZLuD7yy5iHata26rW9faq+oXuHy0kNDPG/huwp6rW/SGTHK6qPaMUN6JVrQtWt7azra6FXJ4luSRJhu1rhnlfXcTc0tgW1d35VuD3k5wG/gu4rcY6xUkLtqjuzg8yeSTdsf+1V7SlVrUuWN3azqq6RrunkV4vXEYjNa1MaJJclOTLSV4Y3neuM+7HU8txDmxhPTcleT7J0ST3zth/fpJHh/1PDU8Pt9wm6rojyfemfqO7FlTXRkupkuSTQ91fT3L1itTVX+JVVSvxAj4B3Dts3ws8sM64Uwuo5RzgReBy4DzgWeCqNWP+APj0sH0b8OiK1HUH8OAS/vu9D7ga+MY6+28GvgQEuBZ4akXqup7JP5Vs+pgrc6YB9gIPDdsPAR9cYi3XAEer6qWq+hHweSb1TZuu9zHghp88Vl9yXUtRGy+l2gs8XBOHgDck2b0CdbWtUmjeVFUnAIb3N64z7oIkh5McSrJVwboUeHnq87Hhu5ljquo0cBK4eIvq6dQF8KHhEuixJG/Z4po2a7O1L0NriddYq5w3JckTwCUzdt3XOMxbq+p4ksuBJ5McqaoXx6nwp2adMdY+ZtzMmLFtZs4vAo9U1Q+T3M3kbPjbW1zXZizj99qMfwV+uf5/idffAz+zxGvaQkNTVe9fb1+S7ybZXVUnhtP2K+sc4/jw/lKSg8C7mFznj+kYMP1/6DcDx9cZcyzJucAOtn6l94Z1VdX0SovPAA9scU2btZnfdOGq6j+mth9P8pdJdtUZlnit0uXZAeD2Yft24AtrByTZmeT8YXsX8F7guS2o5WngiiRvS3Iekxv9tU/qpuu9FXiyhjvLLbRhXWvuE24BvrXFNW3WAeAjw1O0a4GTP7kcX6bXtMRr0U9ZzvCU42Lgn4AXhveLhu/3AJ8dtt8DHGHy1OgIcOcW1nMz8G0mZ7H7hu8+DtwybF8A/B1wFPgX4PIF/U4b1fVnwDeH3+grwK8uqK5HgBPA/zA5q9wJ3A3cPewP8Kmh7iNMFuyuQl33TP1eh4D3bHRMVwRITat0eSZtC4ZGajI0UpOhkZoMjdRkaKQmQyM1GRqp6f8AnwiC0AK+vb8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"imag:\\n\", image)\n",
    "\n",
    "print(\"image.shape\",image.shape)\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                       [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\",weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides = [1,1,1,1],padding='VALID')  # 이 함수 쓰면 자동적으로 계산되는 놀라운 함수 \n",
    "conv2d_img = conv2d.eval() # 값을 뽑기 위해 eval 함수 사용 \n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)  \n",
    "# enumerate 함수 : 리스트가 있는 경우 순서와 리스트의 값을 전달하는 기능\n",
    "#이 함수는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아 인덱스 값을 포함하는 enumerate 객체를 리턴.\n",
    "#보통 enumerate 함수는 for문과 함께 자주 사용됨 \n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding : SAME \n",
    "- 필터 사이즈를 뭐로 하든 간에 stride 1*1 기준일때 convolution해서 나오는 값은 원래 이미지와 크기 같게 해주겠다 \n",
    "- 그럼 부족한 부분에 0을 채워서 계산하게 함으로서 원래 이미지와 같게 해주는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"imag:\\n\", image)\n",
    "\n",
    "print(\"image.shape\",image.shape)\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                       [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\",weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides = [1,1,1,1],padding='SAME')  # 이 함수 쓰면 자동적으로 계산되는 놀라운 함수 \n",
    "conv2d_img = conv2d.eval() # 값을 뽑기 위해 eval 함수 사용 \n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)  \n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 filters(2,2,1,3) # 마지막 3이 필터의 개수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"imag:\\n\", image)\n",
    "\n",
    "print(\"image.shape\",image.shape)\n",
    "weight = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                      [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\",weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides = [1,1,1,1],padding='SAME')  # 이 함수 쓰면 자동적으로 계산되는 놀라운 함수 \n",
    "conv2d_img = conv2d.eval() # 값을 뽑기 위해 eval 함수 사용 \n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)  \n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')\n",
    "# 필터 3개 쓰면 세장의 이미지가 나온다 ! -> 필터를 몇 개 쓰냐에 따라 하나의 이미지에서 여러개의 이미지를 뽑아낼 수 있다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([[[[4],[3]],\n",
    "                   [[2],[1]]]], dtype = np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize = [1,2,2,1],   # 커널 사이즈 \n",
    "                     strides = [1,1,1,1],padding = 'SAME')  # padding same = > 입력과 출력 사이즈가 같다. \n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실전 이미지에 넣어서 동작해보기 \n",
    "## MNIST image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-131b34e31a10>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#데이터 읽어오기 \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- print(\"훈련 이미지 :\",  mnist.train.images.shape)\n",
    "- print(\"훈련 라벨:\",  mnist.train.labels.shape)\n",
    "- print(\"테스트 이미지 : \", mnist.test.images.shape)\n",
    "- print(\"테스트 라벨 : \", mnist.test.labels.shape)\n",
    "- print(\"검증 이미지 : \", mnist.validation.images.shape)\n",
    "- print(\"검증 라벨 : \", mnist.validation.labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23a3aab2d88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Convolution layer\n",
    "## convolution layer 통과시키기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 세션 선언 \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(-1,28,28,1)  # 28 * 28에 색깔 한개(레이어 1), 여러가지 이미지 있으니까 -1\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,5],stddev=0.01)) # 색깔 1개(레이어 크기: 1), 필터 5개 사용 \n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1,2,2,1],padding='SAME')  # padding same 인데 stride 2* 2라서 출력은 14 * 14 될듯 \n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "# 보기좋게 하기위해서, 행렬의 모양을 바꾸어줌 (축을 변형)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1),plt.imshow(one_img.reshape(14,14),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAABZCAYAAAAXQW5UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAJ40lEQVR4nO3dXWhU6RkH8P+TL2KMYdCMBs36UdlVDLUgwVwIgmjrrggLCib4fSVIF0S9qaCIN9I7qeIHoQiKFiliUHHttlcKImhcKrtr4hqT1ETBGk1MNKZJzNMLRx0zM+97ZuacM2/M/weLyTwn5332z8zD5OSdGVFVEBGRu/Jy3QAREZlxUBMROY6DmojIcRzURESO46AmInIcBzURkeMKvBwkIl8D+AuAfAB/VdU/m46PRCJaUVHhQ3vu6ujoQH9//6/wmElxcbGWlpaG01yODA4Ooq+v7y2AdnjIRETGy97QlwCewsN9paysTKPRaGiN5Upra6vnTIDxc19RVUl2u3VQi0g+gKMAfg+gE8BtEbmkqvdS/UxFRQXq6+sz7dV5b9++xcqVKwHgG3jMpLS0FKtXrw6rxdCNjIygoaEBAO4BqIaHTMaRYni8r0SjURw8eDDU5sI2MjKC9evXe86EvF36WAygRVVbVXUQwDkA3wbbltuamppQWFgIZvJRV1cXysrKAGCQmST4H+8rH7W0tADMJC1eBvUMAB1x33fGbhu3urq6UFhYGH/TuM+kv78fEydOjL9p3GcSZzDu63Gfy4sXLwBmkhYvgzrZNZOE60Uisk1EGkWksaenJ/vOHJbiZffGTAYGBoJvzD3GTHLRkCM+ySU+k97e3lz1lGu8rxh4GdSdAL6I+74SwJPRB6lqvapWq2p1JBLxqz8nRaNRDA0Nxd9kzaS4uDi0/nKhpKQEr1+/jr/JmklozeVeUdzXCbnEZxK7fPRZmzx5MmDJBBi395WkvAzq2wC+FJE5IlIEoA7ApWDbctv8+fMxNDQEZvJReXk5Ys8Gi5hJgmLeVz6aO3cuwEzSYh3UqjoM4DsAPwBoAvB3Vf0l6MZcVlBQgKlTpwLM5IO8vDzU1NQAwFdgJqM9Au8rH+Tn5wPMJC2e9lGr6vcAvg+4lzGltLQUqvqV1+PLysqwYsWKlPWNGzdm3VNXV5exHvtre0onTpzIav3KykoA+DnMX1UnTJhgrNsuJTx9+tTPdlJ5yV/fE6SViYjAdPmwrq7Oeo4pU6YY61VVVcb6rVu3jPXjx49be8gUX5lIROQ4DmoiIsdxUBMROY6DmojIcRzURESO46AmInIcBzURkeM4qImIHOfpBS/pKi0txdKlS1PWRZK+N/Ynsn1P3iNHjhjr586dy+r86erv78fdu3dT1jdt2mQ9x7Jly7Lqoba2Nquf91tlZSV2796dsr5hwwbrOWLvG5FS7FVwKV29etVYX7VqlbUHP42MjGBwcDBlffPmzdZzHD582FgvKDA/7I8dO2as792719qD3yKRCJYvX56y/vz5c+s5nj17ZqyfPXvWWLflkpdnf9579OhR6zFJz53RTxERUWg4qImIHMdBTUTkOA5qIiLHcVATETmOg5qIyHEc1EREjgtkH/WrV69w/fr1lPVr165lvUZ5ebmxfvr06azX8NPw8LBxH+eWLVus59ixY4ex3tho/gzQtrY26xph6uzsxM6dO1PWTbX3bHtX9+zZY6zv2rXLWPfyZvDbt2+3HuNVXl4eioqKUtbD2P/f1NRkrC9ZssR6jhs3bvjVDgCgu7sb58+fz+octsfYmTNnjPVTp05lVQe4j5qI6LPFQU1E5DgOaiIix3FQExE5joOaiMhxHNRERI7joCYiclwg+6htotGo9RjbnmHbe+Lu27cvrZ5ybe3atdZjTp48aaz39fUZ69OmTUurp1zr6OiwHmP7f541a5axbnrvZwBobW219hCmGTNmWI+5cOGCsV5TU2Osr1mzxlj3e4+0H7zsuS8uLjbW161bZ6wvXLjQWL9586a1h0zxGTURkeM4qImIHMdBTUTkOA5qIiLHcVATETmOg5qIyHEc1EREjsvJPmrT+zK/Z9snPW/ePGN9//79xvqBAwesPYSpoaHBeszIyIixPmfOHGN9wYIFxvqVK1esPYSpqqrKekxvb6+xvmjRImPdtif48uXL1h7C9PjxY+sxtn3SNnfu3DHW6+rqrOcYGhrKqod0HTp0KOtzlJSUGOsVFRXGupf3Ls+Up0EtIu0A+gC8BTCsqtWBdTRGPHz4ECLyE5jJaL9lLgmYSSJmkoZ0nlEvU9WuwDoZm5hJcswlETNJxEw84jVqIiLHeR3UCuCfInJHRLYlO0BEtolIo4g09vT0+Neho0QESCOTgYGBcBvMrZS5xGeSi8ZyyFMmtmvunxnPj5+wG3ON10G9RFUXAfgGwB9FZOnoA1S1XlWrVbU6Eon42qSLZs6ciXQysb0hzGek2ZRLfCa5aS8nPGdSVlaWmw7DZ8wEGLf3laQ8DWpVfRL7978AGgAsDrKpsaCg4N3lfWaSYAhgLqMwk0TMJA3WQS0iE0Vk0vuvAfwBwM9BN+ayN2/efNgqx0w+im3JygOYyyjMJE7sMiAzSYOXXR/TADTErskWAPibqv4j0K4c193djUePHkFE7oKZfBB7AM5nLgmYSZyXL18CzCQt1kGtqq0AfhdCL2l58OCBsR7kC1qmT5+O2bNno7m52bdcbC9m8aK9vd1Yb2try3oNk0mTJgHAPb+uKfrxh7WtW7ca6xcvXjTWm5ubs+4BPmbih9raWmM9Pz/fWM/2xSyxD7BwKhPg3W/KJj/++KOxfv/+fT/b+QS35xEROY6DmojIcRzURESO46AmInIcBzURkeM4qImIHMdBTUTkOFFV/08q8gzAf+JuKgfg+tsZptvjLFWNej14nGQCpJELM0mUJJNM1wwbHz+JfMskkEGdsIhIo2ub20cLu0dmkvv1MpGLHplL7tfLhJ898tIHEZHjOKiJiBwX1qCuD2mdbITdIzPJ/XqZyEWPzCX362XCtx5DuUZNRESZ46UPIiLHBTqoReRrEbkvIi0i8qcg18qGiLSLyE8i8u+gP5+NmaRcz/lcmEkiZpKc77moaiD/AcgH8BDAbwAUAbgLYEFQ62XZazuA8hDWYSZjOBdmwkxylUuQz6gXA2hR1VZVHQRwDsC3Aa43FjCT5JhLImaSaNxmEuSgngGgI+77zthtLlJYPrreJ8wkubGSCzNJxEyS8zUXL5+ZmClJcpurW0yWqOoTEZkK4F8i0qyq1wNYh5kkN1ZyYSaJmElyvuYS5DPqTgBfxH1fCeBJgOtlTFWfxP4N+qPrmUlyYyIXZpKImSTndy5BDurbAL4UkTkiUgSgDsClANfLiIhMFJFJ779GsB9dz0yScz4XZpKImSQXRC6BXfpQ1WER+Q7AD3j319qTqvpLUOtlYRqABhEBAv7oemaS3BjJhZkkYibJ+Z4LX5lIROQ4vjKRiMhxHNRERI7joCYichwHNRGR4zioiYgcx0FNROQ4DmoiIsdxUBMROe7/Lq+OybDZTC8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize = [1,2,2,1],strides=[\n",
    "                        1,2,2,1], padding='SAME') # 출력이미지는 7 * 7 될 것 \n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1),plt.imshow(one_img.reshape(7,7),cmap='gray') #이미지가 subsampling 되어서 해상도가 낮게 나타날 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - 2 \n",
    "# CNN MNIST : 99% 정확도 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conv layer 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input placeholders\n",
    "# input 읽어오기 \n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "X_img = tf.reshape(X, [-1,28,28,1]) # 이미지 입력으로 넣기 위해 reshape, 28*28의 이미지이고 1개의 색깔을 가지고 있고 n개를 맞추ㅓ봐라. \n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "# X데이터 같은 경우 이번엔 영상 전체를 통으로 입력하지 않기 때문에 [784] - [28, 28]로 reshape을 적용\n",
    "# L1 ImgIn shape=(?,28,28,1) \n",
    "\n",
    "# 3*3 필터크기, 색깔 1개 필터 32개 사용 \n",
    "# 첫번째 층에서 [3 x 3] 마스크를 이용해 32개의 층을 뽑아낸다.\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32],stddev = 0.01)) \n",
    "#  Conv -> (?,28,28,32)\n",
    "#  Pool -> (?,14,14,32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides = [1,1,1,1],padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize = [1,2,2,1],\n",
    "                   strides = [1,2,2,1],padding = 'SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conv layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_2:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L2 ImgIn shape = (?,14,14,32)\n",
    "\n",
    "# 64개의 필터를 쓰겠다. 32개는 그대로 내려옴 \n",
    "#다음 층은 첫번째 32개의 층을 가져와 64개의 층으로 내보낸다.\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64],stddev = 0.01))  \n",
    "#  Conv -> (?,14,14,64)\n",
    "#  Pool -> (?,7,7,64)\n",
    "L2 = tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "print(L2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "print(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "print(L2)\n",
    "\n",
    "# 7*7*64의 크기로 reshape 하겠다 -1의미: n개를 reshape 하겠다. \n",
    "# 다음 출력  [7 * 7] 이미지 64개를 flatten하여 옆으로 길게 나열한다.\n",
    "L2 = tf.reshape(L2, [-1,7*7*64]) \n",
    "print(L2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-9-5a56ed91c551>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final FC 7*7*64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64,10],  # 출력은 10 why? 이건 결과적으로 0~9 안의 숫자를 찍어내는 것이었기 떄문에 \n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2,W3) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost= 0.372833937\n",
      "Epoch: 0002 cost= 0.104354822\n",
      "Epoch: 0003 cost= 0.076842298\n",
      "Epoch: 0004 cost= 0.059552109\n",
      "Epoch: 0005 cost= 0.050868921\n",
      "Epoch: 0006 cost= 0.042163583\n",
      "Epoch: 0007 cost= 0.036882687\n",
      "Epoch: 0008 cost= 0.033461333\n",
      "Epoch: 0009 cost= 0.029055512\n",
      "Epoch: 0010 cost= 0.026092215\n",
      "Epoch: 0011 cost= 0.021126330\n",
      "Epoch: 0012 cost= 0.019972666\n",
      "Epoch: 0013 cost= 0.017517922\n",
      "Epoch: 0014 cost= 0.015498780\n",
      "Epoch: 0015 cost= 0.013973062\n",
      "Learning Finished!\n",
      "Accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0 \n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch): \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y : batch_ys}\n",
    "        c, _, = sess.run([cost, optimizer],feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('Epoch:','%04d' % (epoch + 1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:',sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input placeholders\n",
    "# input 읽어오기 \n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "X_img = tf.reshape(X, [-1,28,28,1]) # 이미지 입력으로 넣기 위해 reshape, 28*28의 이미지이고 1개의 색깔을 가지고 있고 n개를 맞추ㅓ봐라. \n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-dd2b52fe6345>:9: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# L1 ImgIn shape = (?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01))\n",
    "#    Conv   -> (?,28,28,32)\n",
    "#    Pool   -> (?,14,14,32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1],padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],\n",
    "                   strides=[1,2,2,1],padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 ImgIn shape = (?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64],stddev = 0.01))\n",
    "#   Conv   ->  (?,14,14,64)\n",
    "#   Pool   ->  (?,7,7,64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1],padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1],\n",
    "                   strides=[1,2,2,1],padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L3 ImgIn shape = (?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3,3,64,128],stddev = 0.01))\n",
    "#   Conv   ->  (?,7,7,128)\n",
    "#   Pool   ->  (?,4,4,128)\n",
    "#   Reshape -> (?,4*4*128) # flatten them for FC \n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1],padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1],\n",
    "                   strides=[1,2,2,1],padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3 = tf.reshape(L3, [-1, 128*4*4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L4 FC 4*4*128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128*4*4,625],\n",
    "initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3,W4)+b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L5 Final FC 625 inputs -> 10 puts\n",
    "W5 = tf.get_variable(\"W5\",shape=[625,10],\n",
    "initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis  = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss * optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.099383145\n",
      "Epoch: 0002 cost = 0.072244077\n",
      "Epoch: 0003 cost = 0.060652368\n",
      "Epoch: 0004 cost = 0.050228829\n",
      "Epoch: 0005 cost = 0.045682950\n",
      "Epoch: 0006 cost = 0.040825135\n",
      "Epoch: 0007 cost = 0.036678789\n",
      "Epoch: 0008 cost = 0.034663004\n",
      "Epoch: 0009 cost = 0.034849814\n",
      "Epoch: 0010 cost = 0.031458163\n",
      "Epoch: 0011 cost = 0.029072175\n",
      "Epoch: 0012 cost = 0.029010228\n",
      "Epoch: 0013 cost = 0.025715018\n",
      "Epoch: 0014 cost = 0.026439841\n",
      "Epoch: 0015 cost = 0.024997102\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0 \n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y : batch_ys, keep_prob : 0.7}\n",
    "        c, _, = sess.run([cost, optimizer],feed_dict = feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy \n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_sample, y_sample, batch_size = 512):\n",
    "    \"\"\"Run a minibatch accuracy op\"\"\"\n",
    "    \n",
    "    N = X_sample.shape[0]\n",
    "    correct_sample = 0 \n",
    "    \n",
    "    for i in range(0,N, batch_size): \n",
    "        X_batch = X_sample[i: i + batch_size]\n",
    "        y_batch = y_sample[i: i + batch_size]\n",
    "        N_batch = X_batch.shape[0]\n",
    "        \n",
    "        feed = {\n",
    "            X : X_batch,\n",
    "            Y : y_batch,\n",
    "            keep_prob : 1\n",
    "        }\n",
    "        correct_sample += sess.run(accuracy, feed_dict=feed) * N_batch\n",
    "    return correct_sample / N\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Evaluates\n",
      "-------------------------\n",
      "Train Accuracy: 0.9987090909090909\n",
      "Test Accuracy: 0.9936999997138977\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy Evaluates\")\n",
    "print(\"-------------------------\")\n",
    "print('Train Accuracy:', evaluate(mnist.train.images, mnist.train.labels))\n",
    "print('Test Accuracy:', evaluate(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
